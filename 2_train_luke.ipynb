{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "except ModuleNotFoundError as e:\n",
    "    print(\"not in colab\")\n",
    "    pass\n",
    "import os\n",
    "base_dir = \"/content/drive/MyDrive/semeval2022\"\n",
    "if not os.path.exists(base_dir):\n",
    "  !pip install -r requirements.txt\n",
    "  base_dir = \"\"\n",
    "else:\n",
    "  !pip install -r /content/drive/MyDrive/semeval2022/requirements.txt\n",
    "  !cp -rf /content/drive/MyDrive/semeval2022/*.py . \n",
    "  !cp -rf /content/drive/MyDrive/semeval2022/utils .\n",
    "  !cp -rf /content/drive/MyDrive/semeval2022/model ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.util import get_entity_vocab, get_reader, train_model, create_model, save_model, parse_args, get_tagset, wnut_iob, write_submit_result, load_model, luke_iob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = \"distilbert-base-uncased\"\n",
    "encoder_model = \"roberta-base\"\n",
    "encoder_model = \"bert-base-uncased\"\n",
    "encoder_model = \"bert-large-uncased-whole-word-maskin\"\n",
    "encoder_model = \"studio-ousia/luke-base\"\n",
    "track = \"EN-English/en\"\n",
    "train_file = os.path.join(base_dir, \"training_data/{}_train.conll\".format(track))\n",
    "dev_file = os.path.join(base_dir, \"training_data/{}_dev.conll\".format(track))\n",
    "output_dir = os.path.join(base_dir, \"{}\".format(track), \"{}-train\".format(encoder_model))\n",
    "submission_file = os.path.join(base_dir, \"submission\", \"{}.pred.conll\".format(track))\n",
    "iob_tagging = wnut_iob\n",
    "use_crf = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_vocab = get_entity_vocab()\n",
    "train_data = get_reader(file_path=train_file, target_vocab=iob_tagging, encoder_model=encoder_model, max_instances=-1, max_length=100, entity_vocab=entity_vocab)\n",
    "dev_data = get_reader(file_path=dev_file, target_vocab=iob_tagging, encoder_model=encoder_model, max_instances=-1, max_length=100, entity_vocab=entity_vocab)\n",
    "\n",
    "model = create_model(train_data=train_data, dev_data=dev_data, tag_to_id=iob_tagging,\n",
    "                     dropout_rate=0.1, batch_size=32, stage='fit', lr=2e-5,\n",
    "                     encoder_model=encoder_model, num_gpus=1, use_crf=use_crf)\n",
    "\n",
    "trainer = train_model(model=model, out_dir=output_dir, epochs=20, monitor=\"f1\")\n",
    "\n",
    "# use pytorch lightnings saver here.\n",
    "out_model_path, best_checkpoint = save_model(trainer=trainer, out_dir=output_dir, model_name=encoder_model, timestamp=time.time())\n",
    "submission_file = os.path.join(os.path.dirname(out_model_path), \"{}.pred.conll\".format(track))\n",
    "\n",
    "model = load_model(best_checkpoint, iob_tagging, use_crf=use_crf)\n",
    "\n",
    "record_data = write_submit_result(model, dev_data, submission_file)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26273649c1ad55e65f8b33df1791b797f344b761a59a759c3ddbb97d149ed09b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('sem_eval': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
