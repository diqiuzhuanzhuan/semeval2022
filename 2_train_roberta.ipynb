{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "except ModuleNotFoundError as e:\n",
    "    print(\"not in colab\")\n",
    "    in_colab = False\n",
    "import os\n",
    "drive_dir = \"/content/drive/MyDrive/semeval2022\"\n",
    "if not os.path.exists(drive_dir):\n",
    "  in_colab = False\n",
    "  !pip install -r requirements.txt\n",
    "  base_dir = \"\"\n",
    "  drive_dir = \"\"\n",
    "else:\n",
    "  in_colab = True\n",
    "  !cp -rf /content/drive/MyDrive/semeval2022/* .\n",
    "  !pip install -r requirements.txt\n",
    "  base_dir = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.util import get_entity_vocab, get_reader, train_model, test_model, val_model, write_result, create_model, save_model, parse_args, get_tagset, wnut_iob, write_submit_result, write_result, load_model, luke_iob, k_fold, vote, wait_gc\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = \"distilbert-base-uncased\"\n",
    "encoder_model = \"roberta-base\"\n",
    "encoder_model = \"bert-base-uncased\"\n",
    "#encoder_model = \"bert-large-uncased-whole-word-masking\"\n",
    "track = \"EN-English/en\"\n",
    "train_file = os.path.join(base_dir, \"training_data/{}_train.conll\".format(track))\n",
    "dev_file = os.path.join(base_dir, \"training_data/{}_dev.conll\".format(track))\n",
    "test_file = os.path.join(base_dir, \"training_data/{}_test.conll\".format(track))\n",
    "wiki_file = os.path.join(base_dir, \"data/wiki_def/wiki_abstract.vocab\")\n",
    "wiki_file = os.path.join(base_dir, \"data/wiki_def/wiki.pkl.zip\")\n",
    "official_wiki_file = os.path.join(base_dir, \"./data/wiki_def/wikigaz.tsv.zip\")\n",
    "output_dir = os.path.join(base_dir, \"{}\".format(track), \"{}-train\".format(encoder_model))\n",
    "submission_file = os.path.join(drive_dir, \"submission\", \"{}.pred.conll\".format(track))\n",
    "iob_tagging = wnut_iob\n",
    "use_crf = False\n",
    "kl_loss_config = [\n",
    "                  ('B-CW', 'O', 0.3),\n",
    "                  ('I-CW', 'O', 0.3),\n",
    "                  ('B-PROD', 'O', 0.1),\n",
    "                  ('I-PROD', 'O', 0.1),\n",
    "                  ]\n",
    "alpha = 0.3\n",
    "l2_loss_config = [\n",
    "                  (1, 'B-PROD'),\n",
    "                  (1, 'I-PROD'),\n",
    "                  (0.8, 'B-CW'),\n",
    "                  (0.8, 'I-CW'),\n",
    "                  (0.3, 'B-PER'),\n",
    "                  (0.3, 'I-PER')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_for_k_fold(train_file, dev_file):\n",
    "  entity_vocab = get_entity_vocab(conll_files=[], entity_files=[official_wiki_file])\n",
    "  data_augment = []\n",
    "  train_data = get_reader(file_path=train_file, target_vocab=iob_tagging, encoder_model=encoder_model, max_instances=-1, max_length=100, entity_vocab=entity_vocab, augment=data_augment)\n",
    "  dev_entity_vocab = get_entity_vocab(conll_files=[train_file], entity_files=[official_wiki_file])\n",
    "  dev_data = get_reader(file_path=dev_file, target_vocab=iob_tagging, encoder_model=encoder_model, max_instances=-1, max_length=100, entity_vocab=dev_entity_vocab, augment=[])\n",
    "\n",
    "  model = create_model(train_data=train_data, dev_data=dev_data, tag_to_id=iob_tagging,\n",
    "                      dropout_rate=0.1, batch_size=32, stage='fit', lr=2e-5,\n",
    "                      encoder_model=encoder_model, num_gpus=1, use_crf=use_crf, kl_loss_config=kl_loss_config, l2_loss_config=l2_loss_config, alpha=alpha)\n",
    "\n",
    "  trainer = train_model(model=model, out_dir=output_dir, epochs=20, monitor=\"val_micro@F1\")\n",
    "\n",
    "# use pytorch lightnings saver here.\n",
    "  out_model_path, best_checkpoint = save_model(trainer=trainer, out_dir=output_dir, model_name=encoder_model, timestamp=time.time())\n",
    "  model = load_model(best_checkpoint, iob_tagging, use_crf=use_crf)\n",
    "  submission_dev_file = os.path.join(os.path.dirname(out_model_path), \"{}.pred.conll.dev\".format(track))\n",
    "  model.dev_data = dev_data\n",
    "  val_model(model)\n",
    "  write_result(model, submission_dev_file, 'val')\n",
    "  del train_data\n",
    "  del dev_data\n",
    "  del model\n",
    "  del trainer\n",
    "  del dev_entity_vocab\n",
    "  del entity_vocab\n",
    "  return best_checkpoint, out_model_path, submission_dev_file\n",
    "\n",
    "def test(best_checkpoint, out_model_path, test_entity_vocab):\n",
    "  model = load_model(best_checkpoint, iob_tagging, use_crf=use_crf)\n",
    "  test_data = get_reader(file_path=test_file, target_vocab=iob_tagging, encoder_model=encoder_model, max_instances=-1, max_length=100, entity_vocab=test_entity_vocab, augment=[])\n",
    "  model.test_data = test_data\n",
    "  test_model(model)\n",
    "  submission_test_file = os.path.join(os.path.dirname(out_model_path), \"{}.pred.conll.test\".format(track))\n",
    "  write_result(model, submission_test_file, 'test')\n",
    "  del test_data\n",
    "  del model\n",
    "  return submission_test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_files = k_fold(train_file, dev_file, 10)\n",
    "dev_pred_files = []\n",
    "dev_label_files = []\n",
    "test_files = []\n",
    "out_model_paths = []\n",
    "submission_dev_files = []\n",
    "test_entity_vocab = get_entity_vocab(conll_files=[train_file, dev_file], entity_files=[official_wiki_file])\n",
    "\n",
    "for train_file, dev_file in output_files:\n",
    "    best_checkpoint, out_model_path, submission_dev_file = train_for_k_fold(train_file, dev_file)\n",
    "    out_model_paths.append(out_model_path)\n",
    "    dev_label_files.append(dev_file)\n",
    "    dev_pred_files.append(submission_dev_file)\n",
    "    wait_gc()\n",
    "    submission_test_file = test(best_checkpoint, out_model_path, test_entity_vocab)\n",
    "    wait_gc()\n",
    "    test_files.append(submission_test_file)\n",
    "_ = vote(dev_label_files, dev_pred_files, test_files, submission_file, wnut_iob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26273649c1ad55e65f8b33df1791b797f344b761a59a759c3ddbb97d149ed09b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('sem_eval': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
